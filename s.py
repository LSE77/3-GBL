import os
import shutil

# âœ… í´ë” ì‚­ì œ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œí•˜ëŠ” ì•ˆì „í•œ ì‚­ì œ í•¨ìˆ˜ (ì‚¬ìš© ì•ˆí•¨: ì‚­ì œ ë¡œì§ ì œê±°)
def safe_rmtree(path):
    try:
        shutil.rmtree(path)
        print(f"âœ… {path} ì‚­ì œ ì™„ë£Œ")
    except PermissionError:
        print(f"âš ï¸ {path} ì‚­ì œ ì‹¤íŒ¨: íŒŒì¼ì´ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

if __name__ == "__main__":
    from trainer import Trainer, TrainerArgs
    from TTS.config.shared_configs import BaseDatasetConfig
    from TTS.tts.datasets import load_tts_samples
    from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig
    from TTS.utils.manage import ModelManager

    # âœ… ê²½ë¡œ ì„¤ì •
    KSS_DATASET_PATH = "D:/3-GBL/archive/kss/"
    KSS_TRANSCRIPT_PATH = "D:/3-GBL/archive/kss/metadata.csv"
    OUTPUT_PATH = "D:/3-GBL/xtts_training_output/"
    CHECKPOINTS_OUT_PATH = os.path.join(OUTPUT_PATH, "XTTS_v2.0_original_model_files/")
    os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)

    # âœ… ë‹¤ìš´ë¡œë“œ ë§í¬
    TOKENIZER_FILE_LINK = "https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json"
    XTTS_CHECKPOINT_LINK = "https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth"
    DVAE_CHECKPOINT_LINK = "https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth"
    MEL_NORM_LINK = "https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth"

    TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, "vocab.json")
    XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, "model.pth")
    DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, "dvae.pth")
    MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, "mel_stats.pth")

    # âœ… ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not all(os.path.isfile(f) for f in [TOKENIZER_FILE, XTTS_CHECKPOINT, DVAE_CHECKPOINT, MEL_NORM_FILE]):
        print("ğŸ“¥ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        ModelManager._download_model_files(
            [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK, DVAE_CHECKPOINT_LINK, MEL_NORM_LINK],
            CHECKPOINTS_OUT_PATH,
            progress_bar=True
        )

    # âœ… ë°ì´í„°ì…‹ ì„¤ì •
    dataset_config = BaseDatasetConfig(
        formatter="ljspeech",
        dataset_name="kss",
        path=KSS_DATASET_PATH,
        meta_file_train=KSS_TRANSCRIPT_PATH,
        language="ko",
    )

    # âœ… ëª¨ë¸ ì„¤ì •
    model_args = GPTArgs(
        xtts_checkpoint=XTTS_CHECKPOINT,
        tokenizer_file=TOKENIZER_FILE,
        dvae_checkpoint=DVAE_CHECKPOINT,
        mel_norm_file=MEL_NORM_FILE,
        gpt_num_audio_tokens=1026,
        gpt_start_audio_token=1024,
        gpt_stop_audio_token=1025,
        gpt_use_masking_gt_prompt_approach=True,
        gpt_use_perceiver_resampler=True,
    )

    audio_config = XttsAudioConfig(
        sample_rate=22050,
        dvae_sample_rate=22050,
        output_sample_rate=24000
    )

    trainer_config = GPTTrainerConfig(
    output_path=OUTPUT_PATH,
    model_args=model_args,
    run_name="XTTS_KSS_finetune",
    project_name="KSS_XTTS",
    dashboard_logger="tensorboard",
    logger_uri=None,
    audio=audio_config,
    batch_size=4,
    batch_group_size=48,
    eval_batch_size=4,
    num_loader_workers=4,
    print_step=50,
    plot_step=100,
    save_step=100,             # âœ… ë” ìì£¼ ì €ì¥í•˜ë„ë¡ ë³€ê²½
    save_n_checkpoints=5,      # âœ… ìµœê·¼ 5ê°œê¹Œì§€ ë³´ì¡´
    save_checkpoints=True,
    optimizer="AdamW",
    optimizer_params={"betas": [0.9, 0.96], "eps": 1e-8, "weight_decay": 1e-2},
    lr=5e-06,
    epochs=10,                # âœ… ì¶”ê°€: ì›í•˜ëŠ” epoch ìˆ˜ ì„¤ì •
    test_sentences=[
        {
            "text": "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” í”„ë¦¬ë Œì²˜ëŸ¼ ì¡°ìš©í•œ ìºë¦­í„°ì…ë‹ˆë‹¤.",
            "speaker_wav": ["D:/3-GBL/archive/kss/wavs/1_0000.wav"],
            "language": "ko",
        },
    ],
)


    # âœ… ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    DATASETS_CONFIG_LIST = [dataset_config]
    model = GPTTrainer.init_from_config(trainer_config)
    train_samples, eval_samples = load_tts_samples(
        DATASETS_CONFIG_LIST,
        eval_split=True,
        eval_split_max_size=256,
    )

    # âœ… í•™ìŠµ ì‹œì‘
    print("ğŸš€ XTTS Fine-tuning ì‹œì‘...")
    trainer = Trainer(
        TrainerArgs(restore_path=None),
        trainer_config,
        output_path=OUTPUT_PATH,
        model=model,
        train_samples=train_samples,
        eval_samples=eval_samples,
    )
    trainer.fit()

    # âœ… í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ê°•ì œ ì €ì¥
    print("ğŸ’¾ í•™ìŠµ ì™„ë£Œ: ëª¨ë¸ ì €ì¥ ì¤‘...")
    model.save_checkpoint(os.path.join(OUTPUT_PATH, "best_model.pth"))
    print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ.")
